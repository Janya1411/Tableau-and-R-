#### Tutorial: Thursday 4:15 {style="text-align: right;"}
# Change the directory to the folder where the R file is stored
script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
#setting working directory
setwd(script_dir)
train_df = read.table("XGtrainRain.txt", header = TRUE, sep=",")
test_df = read.table("XGtestRain.txt", header = TRUE, sep=",")
library(MASS)
qda.model = qda(G ~ .,data=train_df)
logistic.model = glm(G ~ ., data=train_df, family=binomial(link = "logit"), control = glm.control(maxit = 100))
# center the training set
train_Xc = scale(train_df[, -366], scale = FALSE)
prcomp_res = prcomp(train_Xc, retx = TRUE)
X_bar = colMeans(train_df[, -366])
pcs = as.matrix(train_Xc) %*% prcomp_res$rotation
get_best_q = function(data = train_df, q_max = 30){
logistic_cv_errors = numeric(q_max)
comp = pcs
# perform LOOCV for a range of q values: (2, q.max)
for(q in 2:q_max){
error_logistic = 0
# perform LOOCV for each q
for(i in 1:nrow(train_df)){
cv_data = data.frame(comp[, 1:q], G=train_df[, 366])
cv_data_train = cv_data[-i,]
newdata = cv_data[i, 1:q]
true_label = cv_data[i, q+1]
# train on everything except i-th row
logistic_cv = glm(G ~ ., data = cv_data_train,
family=binomial(link = "logit"))
# prediction on i-th row
logistic_pred = round(predict(logistic_cv, newdata = newdata,
type = "response"))
# count misclassifications
if(logistic_pred!=true_label){
error_logistic = error_logistic + 1
}
}
logistic_cv_errors[q] = error_logistic
}
return(list(logistic = logistic_cv_errors))
}
q_max = 30
pca_cv = get_best_q()
# best q (optimal number of principal components for logistic classfier)
(logistic_pca_best_q = which.min(pca_cv$logistic[2:q_max]) + 1)
# misclassifications for q = 2:q.max
print(pca_cv$logistic[2:q_max])
plot(2:q_max, pca_cv$logistic[2:q_max], type = "l", xlab = "PCA components", ylab = "LOCV errors")
plot(2:q_max, pca_cv$logistic[2:q_max], type = "l", xlab = "PCA components", ylab = "LOCV errors")
get_test_prediction = function(train_df, test_df, q){
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pcs_test = as.matrix(test_Xc) %*% prcomp_res$rotation
comp = pcs
comp_test = pcs_test
train_comp = data.frame(comp[, 1:q], G=train_df[, 366])
test_comp = data.frame(comp_test[, 1:q], G=test_df[, 366])
target_model = NaN
# train
logistic_best = glm(G ~ ., data = train_comp,
family=binomial(link = "logit"))
# test
logistic_pred = round(predict(logistic_best, newdata =   test_comp[, 1:q],
type = "response"))
# misclassifications
logistic_error = sum(logistic_pred!=test_comp$G)
classification_error <- mean(logistic_pred!= test.df$G)
print(classification_error)
return(logistic_error)
}
get_test_prediction(train_df, test_df, q=logistic_pca_best_q)
library(randomForest)
set.seed(123)
c <- sqrt(365)
candidate_m <- c(round(c / 4), round(c / 2), round(c), round(2 * c), round(3 * c), round(4 * c), round(5 * c), round(6 * c), round(7 * c), round(8 * c))
oob_error_df <- data.frame(m = candidate_m, oob_error = rep(NA, length(candidate_m)))
for (i in 1:length(candidate_m)) {
rf <- randomForest(factor(G) ~ ., data = train_df, ntree = 5000,
mtry = candidate_m[i])
oob_error_df$oob_error[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
}
best_m <- oob_error_df$m[which.min(oob_error_df$oob_error)]
print(oob_error_df)
print(best_m)
rf_model_best <- randomForest(factor(G) ~ ., data = train.df, ntree = 5000, mtry = best_m, importance = TRUE)
varImpPlot(rf_model_best, main = "Gini Importance of Variables")
imp.var <- c(12, 24, 37, 32)
par(mfrow = c(2, 2))
for (var in imp.var) {
south <- train.df[train.df$G == 1, var]
north <- train.df[train.df$G == 0, var]
# Create labels for the boxplots
labels <- c("N", "S")
data <- list(north, south)
boxplot(data, names = labels, main = sprintf("Day %s", var))
}
test_predictions <- predict(rf_model_best, newdata = test.df, type = "response")
classification_error <- mean(test_predictions != test.df$G)
print(sum(test_predictions!=test.df$G))
classification_error
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train.df,ncomp=50)
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pls_train = as.matrix(train_Xc) %*% pls_model$projection
training = data.frame(pls_train, G=train.df[, 366])
test = data.frame(pls_test[, 1:50], G=test_df[, 366])
tree_model <- rpart(G ~.,data=training,method= 'class')
rpart.plot(tree_model,type = 4)
selected_components <- c(1, 2)
selected_X = c(12,24, 32, 37)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X12', 'X24', 'X32', 'X37')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X32', 'X37'),col=1:4,pch=1)
---
title: "MS_Assignmen_3"
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
print(sum(test_pred_pls!=test.df$G))
classification_error <- mean(test_pred_pls != test.df$G)
classification_error
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
# Change the directory to the folder where the R file is stored
script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
#setting working directory
setwd(script_dir)
train_df = read.table("XGtrainRain.txt", header = TRUE, sep=",")
test_df = read.table("XGtestRain.txt", header = TRUE, sep=",")
library(MASS)
qda.model = qda(G ~ .,data=train_df)
logistic.model = glm(G ~ ., data=train_df, family=binomial(link = "logit"), control = glm.control(maxit = 100))
# center the training set
train_Xc = scale(train_df[, -366], scale = FALSE)
prcomp_res = prcomp(train_Xc, retx = TRUE)
X_bar = colMeans(train_df[, -366])
pcs = as.matrix(train_Xc) %*% prcomp_res$rotation
get_best_q = function(data = train_df, q_max = 30){
logistic_cv_errors = numeric(q_max)
comp = pcs
# perform LOOCV for a range of q values: (2, q.max)
for(q in 2:q_max){
error_logistic = 0
# perform LOOCV for each q
for(i in 1:nrow(train_df)){
cv_data = data.frame(comp[, 1:q], G=train_df[, 366])
cv_data_train = cv_data[-i,]
newdata = cv_data[i, 1:q]
true_label = cv_data[i, q+1]
# train on everything except i-th row
logistic_cv = glm(G ~ ., data = cv_data_train,
family=binomial(link = "logit"))
# prediction on i-th row
logistic_pred = round(predict(logistic_cv, newdata = newdata,
type = "response"))
# count misclassifications
if(logistic_pred!=true_label){
error_logistic = error_logistic + 1
}
}
logistic_cv_errors[q] = error_logistic
}
return(list(logistic = logistic_cv_errors))
}
q_max = 30
pca_cv = get_best_q()
# best q (optimal number of principal components for logistic classfier)
(logistic_pca_best_q = which.min(pca_cv$logistic[2:q_max]) + 1)
# misclassifications for q = 2:q.max
print(pca_cv$logistic[2:q_max])
plot(2:q_max, pca_cv$logistic[2:q_max], type = "l", xlab = "PCA components", ylab = "LOCV errors")
plot(2:q_max, pca_cv$logistic[2:q_max], type = "l", xlab = "PCA components", ylab = "LOCV errors")
get_test_prediction = function(train_df, test_df, q){
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pcs_test = as.matrix(test_Xc) %*% prcomp_res$rotation
comp = pcs
comp_test = pcs_test
train_comp = data.frame(comp[, 1:q], G=train_df[, 366])
test_comp = data.frame(comp_test[, 1:q], G=test_df[, 366])
target_model = NaN
# train
logistic_best = glm(G ~ ., data = train_comp,
family=binomial(link = "logit"))
# test
logistic_pred = round(predict(logistic_best, newdata =   test_comp[, 1:q],
type = "response"))
# misclassifications
logistic_error = sum(logistic_pred!=test_comp$G)
classification_error <- mean(logistic_pred!= test.df$G)
print(classification_error)
return(logistic_error)
}
get_test_prediction(train_df, test_df, q=logistic_pca_best_q)
get_test_prediction = function(train_df, test_df, q){
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pcs_test = as.matrix(test_Xc) %*% prcomp_res$rotation
comp = pcs
comp_test = pcs_test
train_comp = data.frame(comp[, 1:q], G=train_df[, 366])
test_comp = data.frame(comp_test[, 1:q], G=test_df[, 366])
target_model = NaN
# train
logistic_best = glm(G ~ ., data = train_comp,
family=binomial(link = "logit"))
# test
logistic_pred = round(predict(logistic_best, newdata =   test_comp[, 1:q],
type = "response"))
# misclassifications
logistic_error = sum(logistic_pred!=test_comp$G)
classification_error <- mean(logistic_pred!= test_df$G)
print(classification_error)
return(logistic_error)
}
get_test_prediction(train_df, test_df, q=logistic_pca_best_q)
library(randomForest)
set.seed(123)
c <- sqrt(365)
candidate_m <- c(round(c / 4), round(c / 2), round(c), round(2 * c), round(3 * c), round(4 * c), round(5 * c), round(6 * c), round(7 * c), round(8 * c))
oob_error_df <- data.frame(m = candidate_m, oob_error = rep(NA, length(candidate_m)))
for (i in 1:length(candidate_m)) {
rf <- randomForest(factor(G) ~ ., data = train_df, ntree = 5000,
mtry = candidate_m[i])
oob_error_df$oob_error[i] <- rf$err.rate[nrow(rf$err.rate), "OOB"]
}
best_m <- oob_error_df$m[which.min(oob_error_df$oob_error)]
print(oob_error_df)
print(best_m)
rf_model_best <- randomForest(factor(G) ~ ., data = train.df, ntree = 5000, mtry = best_m, importance = TRUE)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_components <- c(1, 2)
selected_X = c(12,24, 32, 37)
selected_comp = pls_model$scores[, selected_components]
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train.df,ncomp=50)
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train_df,ncomp=50)
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pls_train = as.matrix(train_Xc) %*% pls_model$projection
training = data.frame(pls_train, G=train.df[, 366])
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train_df,ncomp=50)
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pls_train = as.matrix(train_Xc) %*% pls_model$projection
training = data.frame(pls_train, G=train_df[, 366])
test = data.frame(pls_test[, 1:50], G=test_df[, 366])
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train_df,ncomp=50)
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pls_train = as.matrix(train_Xc) %*% pls_model$projection
pls_train = as.matrix(test_Xc) %*% pls_model$projection
training = data.frame(pls_train, G=train_df[, 366])
library(pls)
library(rpart)
library(rpart.plot)
X_bar = colMeans(train_df[, -366])
pls_model = plsr(G ~ ., data=train_df,ncomp=50)
n_test = nrow(test_df)
test_Xc = test_df[, -366] - matrix(rep(X_bar, n_test), nrow = n_test, byrow = TRUE)
pls_train = as.matrix(train_Xc) %*% pls_model$projection
pls_test = as.matrix(test_Xc) %*% pls_model$projection
training = data.frame(pls_train, G=train_df[, 366])
test = data.frame(pls_test[, 1:50], G=test_df[, 366])
tree_model <- rpart(G ~.,data=training,method= 'class')
rpart.plot(tree_model,type = 4)
selected_components <- c(1, 2)
selected_X = c(12,24, 32, 37)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
selected_components <- c(1, 2)
selected_X = c(12,24, 32, 37)
selected_comp = pls_model$scores[, selected_components]
selected_X = train_Xc[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X12', 'X24', 'X32', 'X37')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X32', 'X37'),col=1:4,pch=1)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = X_train[, selected_X]
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = train_Xc[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = train_Xc[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
plot(correlation_matrix[, 1], correlation_matrix[, 2], xlim = c(-2, 2), ylim = c(-1,1),xlab= 'PLS 1',ylab = 'PLS 2')
radius = 1
theta = seq(0, 2 * pi, length = 200)
lines(x = radius * cos(theta), y = radius * sin(theta))
arrows(0, 0, correlation_matrix[, 1], correlation_matrix[, 2], col = 1:4)
labels = c('X1', 'X2', 'X3', 'X4')
text(correlation_matrix[, 1], correlation_matrix[, 2], labels, col = 1:4, pos = 2)
legend(x="topright",legend = c('X12', 'X24', 'X37', 'X32'),col=1:4,pch=1)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
print(sum(test_pred_pls!=test.df$G))
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
print(sum(test_pred_pls!=test_df$G))
classification_error <- mean(test_pred_pls != test.df$G)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
print(sum(test_pred_pls!=test_df$G))
classification_error <- mean(test_pred_pls != test_df$G)
classification_error
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
print(sum(test_pred_pls!=test_df$G))
classification_error <- mean(test_pred_pls != test_df$G)
print(classification_error)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
#print(sum(test_pred_pls!=test_df$G))
classification_error <- mean(test_pred_pls != test_df$G)
print(classification_error)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
classification_error <- mean(test_pred_pls != test_df$G)
print(sum(test_pred_pls!=test_df$G))
print(classification_error)
test_pred_pls <- predict(tree_model,newdata=data.frame(pls_test))
test_pred_pls  = as.data.frame(test_pred_pls)
test_pred_pls$new_data <- as.integer(lapply(seq_len(nrow(test_pred_pls)), function(i) test_pred_pls[i, "0"] < test_pred_pls[i, "1"]))
test_pred_pls=unlist(test_pred_pls$new_data)
classification_error <- mean(test_pred_pls != test_df$G)
print(sum(test_pred_pls!=test_df$G))
print(classification_error)
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = train_Xc[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
correlation_matrix
selected_components <- c(1, 2)
selected_X = c(154,170, 185, 190)
selected_comp = pls_model$scores[, selected_components]
selected_X = train_Xc[, selected_X]
correlation_matrix <- cor(selected_X,selected_comp)
print(correlation_matrix)
